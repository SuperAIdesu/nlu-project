{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "baa62070-661c-43a6-91cb-a3c9b6f189fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ext3/miniconda3/envs/owl-botu/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9230a56-4203-4c8a-9577-48d7667a1bd2",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c6e423d-4887-439b-b020-a39c00aae4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else \"cpu\"\n",
    "model_name = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "access_token = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "932ac52e-98f7-430f-9532-bf152b7aa668",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading tokenizer_config.json: 100%|██████████| 51.0k/51.0k [00:00<00:00, 14.8MB/s]\n",
      "Downloading tokenizer.json: 100%|██████████| 9.09M/9.09M [00:00<00:00, 25.0MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 73.0/73.0 [00:00<00:00, 499kB/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Downloading config.json: 100%|██████████| 654/654 [00:00<00:00, 5.04MB/s]\n",
      "Downloading (…)fetensors.index.json: 100%|██████████| 23.9k/23.9k [00:00<00:00, 67.6MB/s]\n",
      "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Downloading (…)of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:   1%|          | 31.5M/4.98G [00:00<00:17, 278MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:   2%|▏         | 83.9M/4.98G [00:00<00:13, 372MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:   3%|▎         | 126M/4.98G [00:00<00:13, 358MB/s] \u001b[A\n",
      "Downloading (…)of-00004.safetensors:   3%|▎         | 168M/4.98G [00:00<00:13, 350MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:   4%|▍         | 210M/4.98G [00:00<00:15, 309MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:   5%|▌         | 252M/4.98G [00:00<00:15, 312MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:   6%|▌         | 294M/4.98G [00:00<00:14, 316MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:   7%|▋         | 336M/4.98G [00:01<00:15, 294MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:   7%|▋         | 367M/4.98G [00:01<00:15, 295MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:   8%|▊         | 409M/4.98G [00:01<00:16, 277MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:   9%|▉         | 440M/4.98G [00:01<00:15, 285MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  10%|▉         | 482M/4.98G [00:01<00:14, 305MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  11%|█         | 524M/4.98G [00:01<00:13, 320MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  11%|█▏        | 566M/4.98G [00:01<00:17, 251MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  12%|█▏        | 598M/4.98G [00:02<00:17, 255MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  13%|█▎        | 629M/4.98G [00:02<00:16, 264MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  13%|█▎        | 661M/4.98G [00:02<00:15, 271MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  14%|█▍        | 692M/4.98G [00:02<00:16, 263MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  15%|█▍        | 724M/4.98G [00:02<00:19, 223MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  15%|█▌        | 755M/4.98G [00:02<00:17, 242MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  16%|█▌        | 786M/4.98G [00:02<00:16, 256MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  17%|█▋        | 828M/4.98G [00:02<00:14, 294MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  17%|█▋        | 860M/4.98G [00:03<00:14, 291MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  18%|█▊        | 891M/4.98G [00:03<00:14, 285MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  19%|█▉        | 933M/4.98G [00:03<00:12, 319MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  20%|█▉        | 975M/4.98G [00:03<00:12, 310MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  20%|██        | 1.02G/4.98G [00:03<00:12, 307MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  21%|██        | 1.05G/4.98G [00:03<00:13, 301MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  22%|██▏       | 1.08G/4.98G [00:03<00:13, 292MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  23%|██▎       | 1.12G/4.98G [00:03<00:12, 315MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  23%|██▎       | 1.16G/4.98G [00:04<00:13, 275MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  24%|██▍       | 1.20G/4.98G [00:04<00:14, 270MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  25%|██▍       | 1.24G/4.98G [00:04<00:13, 285MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  25%|██▌       | 1.27G/4.98G [00:04<00:13, 282MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  26%|██▋       | 1.31G/4.98G [00:04<00:12, 284MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  27%|██▋       | 1.34G/4.98G [00:04<00:13, 279MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  28%|██▊       | 1.37G/4.98G [00:04<00:12, 288MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  28%|██▊       | 1.42G/4.98G [00:04<00:11, 309MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  29%|██▉       | 1.46G/4.98G [00:05<00:11, 317MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  30%|███       | 1.51G/4.98G [00:05<00:09, 352MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  31%|███       | 1.55G/4.98G [00:05<00:09, 343MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  32%|███▏      | 1.59G/4.98G [00:05<00:10, 312MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  33%|███▎      | 1.64G/4.98G [00:05<00:10, 325MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  34%|███▎      | 1.68G/4.98G [00:05<00:09, 338MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  35%|███▍      | 1.72G/4.98G [00:05<00:09, 357MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  35%|███▌      | 1.76G/4.98G [00:05<00:09, 357MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  36%|███▌      | 1.80G/4.98G [00:06<00:09, 351MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  37%|███▋      | 1.85G/4.98G [00:06<00:09, 341MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  38%|███▊      | 1.89G/4.98G [00:06<00:08, 352MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  39%|███▉      | 1.93G/4.98G [00:06<00:09, 318MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  40%|███▉      | 1.97G/4.98G [00:06<00:09, 329MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  40%|████      | 2.01G/4.98G [00:06<00:09, 319MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  41%|████▏     | 2.06G/4.98G [00:06<00:09, 317MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  42%|████▏     | 2.10G/4.98G [00:06<00:09, 310MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  43%|████▎     | 2.13G/4.98G [00:07<00:09, 305MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  44%|████▎     | 2.17G/4.98G [00:07<00:08, 316MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  45%|████▍     | 2.22G/4.98G [00:07<00:08, 335MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  46%|████▌     | 2.26G/4.98G [00:07<00:08, 330MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  46%|████▋     | 2.31G/4.98G [00:07<00:08, 332MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  47%|████▋     | 2.35G/4.98G [00:07<00:08, 305MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  48%|████▊     | 2.38G/4.98G [00:07<00:10, 255MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  49%|████▊     | 2.42G/4.98G [00:08<00:09, 277MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  49%|████▉     | 2.45G/4.98G [00:08<00:09, 274MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  50%|████▉     | 2.49G/4.98G [00:08<00:10, 232MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  51%|█████     | 2.53G/4.98G [00:08<00:09, 263MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  51%|█████▏    | 2.56G/4.98G [00:08<00:09, 256MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  52%|█████▏    | 2.59G/4.98G [00:08<00:09, 258MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  53%|█████▎    | 2.63G/4.98G [00:08<00:08, 270MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  54%|█████▎    | 2.66G/4.98G [00:08<00:08, 277MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  54%|█████▍    | 2.71G/4.98G [00:09<00:07, 306MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  55%|█████▍    | 2.74G/4.98G [00:09<00:07, 307MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  56%|█████▌    | 2.78G/4.98G [00:09<00:07, 306MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  56%|█████▋    | 2.81G/4.98G [00:09<00:07, 282MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  57%|█████▋    | 2.84G/4.98G [00:09<00:07, 285MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  58%|█████▊    | 2.88G/4.98G [00:09<00:06, 302MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  59%|█████▊    | 2.92G/4.98G [00:09<00:06, 298MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  59%|█████▉    | 2.95G/4.98G [00:09<00:08, 253MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  60%|█████▉    | 2.98G/4.98G [00:10<00:07, 264MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  61%|██████    | 3.02G/4.98G [00:10<00:07, 273MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  61%|██████▏   | 3.05G/4.98G [00:10<00:07, 248MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  62%|██████▏   | 3.09G/4.98G [00:10<00:06, 273MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  63%|██████▎   | 3.14G/4.98G [00:10<00:06, 287MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  64%|██████▎   | 3.17G/4.98G [00:10<00:07, 255MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  64%|██████▍   | 3.20G/4.98G [00:10<00:06, 263MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  65%|██████▌   | 3.24G/4.98G [00:11<00:06, 272MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  66%|██████▌   | 3.27G/4.98G [00:11<00:06, 259MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  67%|██████▋   | 3.31G/4.98G [00:11<00:05, 291MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  67%|██████▋   | 3.36G/4.98G [00:11<00:05, 279MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  68%|██████▊   | 3.39G/4.98G [00:11<00:05, 280MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  69%|██████▉   | 3.43G/4.98G [00:11<00:05, 282MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  70%|██████▉   | 3.46G/4.98G [00:11<00:06, 234MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  70%|███████   | 3.49G/4.98G [00:12<00:06, 244MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  71%|███████   | 3.52G/4.98G [00:12<00:05, 244MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  71%|███████▏  | 3.55G/4.98G [00:12<00:06, 231MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  72%|███████▏  | 3.59G/4.98G [00:12<00:06, 202MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  73%|███████▎  | 3.62G/4.98G [00:12<00:06, 209MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  73%|███████▎  | 3.65G/4.98G [00:12<00:06, 215MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  74%|███████▍  | 3.69G/4.98G [00:12<00:05, 247MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  75%|███████▍  | 3.72G/4.98G [00:13<00:06, 188MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  75%|███████▌  | 3.75G/4.98G [00:13<00:05, 207MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  76%|███████▌  | 3.79G/4.98G [00:13<00:08, 145MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  76%|███████▋  | 3.81G/4.98G [00:13<00:08, 146MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  77%|███████▋  | 3.84G/4.98G [00:13<00:06, 172MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  78%|███████▊  | 3.88G/4.98G [00:14<00:05, 211MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  79%|███████▊  | 3.91G/4.98G [00:14<00:05, 197MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  79%|███████▉  | 3.94G/4.98G [00:14<00:05, 204MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  80%|████████  | 3.98G/4.98G [00:14<00:04, 235MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  81%|████████  | 4.02G/4.98G [00:14<00:04, 234MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  81%|████████▏ | 4.05G/4.98G [00:14<00:04, 225MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  82%|████████▏ | 4.08G/4.98G [00:14<00:03, 237MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  83%|████████▎ | 4.11G/4.98G [00:15<00:03, 252MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  83%|████████▎ | 4.14G/4.98G [00:15<00:03, 267MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  84%|████████▍ | 4.17G/4.98G [00:15<00:02, 277MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  85%|████████▍ | 4.22G/4.98G [00:15<00:02, 304MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  86%|████████▌ | 4.26G/4.98G [00:15<00:02, 320MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  86%|████████▋ | 4.30G/4.98G [00:15<00:02, 327MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  87%|████████▋ | 4.34G/4.98G [00:15<00:01, 322MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  88%|████████▊ | 4.38G/4.98G [00:15<00:01, 345MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  89%|████████▉ | 4.44G/4.98G [00:15<00:01, 372MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  90%|████████▉ | 4.48G/4.98G [00:16<00:01, 355MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  91%|█████████ | 4.52G/4.98G [00:16<00:01, 349MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  92%|█████████▏| 4.56G/4.98G [00:16<00:01, 354MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  92%|█████████▏| 4.60G/4.98G [00:16<00:01, 359MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  93%|█████████▎| 4.65G/4.98G [00:16<00:00, 367MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  94%|█████████▍| 4.69G/4.98G [00:16<00:00, 369MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  95%|█████████▌| 4.73G/4.98G [00:16<00:00, 381MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  96%|█████████▌| 4.77G/4.98G [00:16<00:00, 370MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  97%|█████████▋| 4.81G/4.98G [00:16<00:00, 361MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  98%|█████████▊| 4.85G/4.98G [00:17<00:00, 354MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  98%|█████████▊| 4.90G/4.98G [00:17<00:00, 366MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  99%|█████████▉| 4.94G/4.98G [00:17<00:00, 355MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors: 100%|██████████| 4.98G/4.98G [00:17<00:00, 284MB/s]\u001b[A\n",
      "Downloading shards:  25%|██▌       | 1/4 [00:17<00:52, 17.63s/it]\n",
      "Downloading (…)of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:   1%|          | 41.9M/5.00G [00:00<00:14, 352MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:   2%|▏         | 83.9M/5.00G [00:00<00:13, 377MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:   3%|▎         | 126M/5.00G [00:00<00:14, 342MB/s] \u001b[A\n",
      "Downloading (…)of-00004.safetensors:   3%|▎         | 168M/5.00G [00:00<00:14, 329MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:   4%|▍         | 210M/5.00G [00:00<00:16, 284MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:   5%|▍         | 241M/5.00G [00:00<00:16, 288MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:   5%|▌         | 273M/5.00G [00:00<00:16, 290MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:   6%|▌         | 304M/5.00G [00:01<00:16, 280MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:   7%|▋         | 336M/5.00G [00:01<00:17, 270MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:   8%|▊         | 377M/5.00G [00:01<00:16, 279MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:   8%|▊         | 409M/5.00G [00:01<00:17, 262MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:   9%|▉         | 451M/5.00G [00:01<00:15, 287MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  10%|▉         | 493M/5.00G [00:01<00:14, 314MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  11%|█         | 535M/5.00G [00:01<00:14, 319MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  12%|█▏        | 577M/5.00G [00:01<00:13, 338MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  12%|█▏        | 619M/5.00G [00:02<00:13, 330MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  13%|█▎        | 661M/5.00G [00:02<00:12, 346MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  14%|█▍        | 703M/5.00G [00:02<00:12, 352MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  15%|█▍        | 744M/5.00G [00:02<00:11, 366MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  16%|█▌        | 786M/5.00G [00:02<00:11, 367MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  17%|█▋        | 828M/5.00G [00:02<00:11, 364MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  17%|█▋        | 870M/5.00G [00:02<00:11, 349MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  18%|█▊        | 912M/5.00G [00:02<00:11, 354MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  19%|█▉        | 954M/5.00G [00:02<00:12, 320MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  20%|█▉        | 996M/5.00G [00:03<00:13, 293MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  21%|██        | 1.04G/5.00G [00:03<00:12, 306MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  21%|██▏       | 1.07G/5.00G [00:03<00:13, 299MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  22%|██▏       | 1.11G/5.00G [00:03<00:12, 311MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  23%|██▎       | 1.16G/5.00G [00:03<00:11, 347MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  24%|██▍       | 1.21G/5.00G [00:03<00:10, 353MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  25%|██▍       | 1.25G/5.00G [00:03<00:10, 350MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  26%|██▌       | 1.29G/5.00G [00:03<00:10, 359MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  27%|██▋       | 1.33G/5.00G [00:04<00:11, 322MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  27%|██▋       | 1.37G/5.00G [00:04<00:10, 334MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  28%|██▊       | 1.42G/5.00G [00:04<00:11, 313MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  29%|██▉       | 1.46G/5.00G [00:04<00:11, 319MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  30%|██▉       | 1.50G/5.00G [00:04<00:10, 322MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  31%|███       | 1.54G/5.00G [00:04<00:11, 298MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  32%|███▏      | 1.58G/5.00G [00:04<00:11, 305MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  32%|███▏      | 1.61G/5.00G [00:05<00:11, 282MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  33%|███▎      | 1.65G/5.00G [00:05<00:12, 276MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  34%|███▎      | 1.68G/5.00G [00:05<00:11, 283MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  34%|███▍      | 1.72G/5.00G [00:05<00:10, 299MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  35%|███▌      | 1.75G/5.00G [00:05<00:10, 297MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  36%|███▌      | 1.79G/5.00G [00:05<00:10, 310MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  36%|███▋      | 1.82G/5.00G [00:05<00:10, 305MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  37%|███▋      | 1.86G/5.00G [00:05<00:10, 297MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  38%|███▊      | 1.89G/5.00G [00:06<00:10, 294MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  38%|███▊      | 1.92G/5.00G [00:06<00:10, 297MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  39%|███▉      | 1.96G/5.00G [00:06<00:09, 325MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  40%|████      | 2.00G/5.00G [00:06<00:08, 349MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  41%|████      | 2.06G/5.00G [00:06<00:07, 384MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  42%|████▏     | 2.10G/5.00G [00:06<00:07, 383MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  43%|████▎     | 2.14G/5.00G [00:06<00:08, 356MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  44%|████▎     | 2.18G/5.00G [00:06<00:09, 311MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  44%|████▍     | 2.22G/5.00G [00:07<00:09, 295MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  45%|████▌     | 2.25G/5.00G [00:07<00:09, 284MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  46%|████▌     | 2.29G/5.00G [00:07<00:09, 290MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  47%|████▋     | 2.33G/5.00G [00:07<00:08, 299MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  48%|████▊     | 2.38G/5.00G [00:07<00:07, 334MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  48%|████▊     | 2.42G/5.00G [00:07<00:08, 305MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  49%|████▉     | 2.45G/5.00G [00:07<00:08, 301MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  50%|████▉     | 2.50G/5.00G [00:07<00:08, 308MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  51%|█████     | 2.54G/5.00G [00:08<00:07, 319MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  52%|█████▏    | 2.58G/5.00G [00:08<00:07, 331MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  52%|█████▏    | 2.62G/5.00G [00:08<00:07, 331MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  53%|█████▎    | 2.66G/5.00G [00:08<00:07, 307MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  54%|█████▍    | 2.71G/5.00G [00:08<00:07, 316MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  55%|█████▍    | 2.75G/5.00G [00:08<00:06, 333MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  56%|█████▌    | 2.79G/5.00G [00:08<00:06, 336MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  57%|█████▋    | 2.83G/5.00G [00:08<00:06, 331MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  57%|█████▋    | 2.87G/5.00G [00:09<00:07, 300MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  58%|█████▊    | 2.92G/5.00G [00:09<00:06, 320MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  59%|█████▉    | 2.96G/5.00G [00:09<00:06, 321MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  60%|█████▉    | 3.00G/5.00G [00:09<00:06, 330MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  61%|██████    | 3.04G/5.00G [00:09<00:05, 334MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  62%|██████▏   | 3.08G/5.00G [00:09<00:06, 298MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  62%|██████▏   | 3.11G/5.00G [00:09<00:06, 294MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  63%|██████▎   | 3.15G/5.00G [00:09<00:06, 299MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  64%|██████▍   | 3.19G/5.00G [00:10<00:05, 305MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  65%|██████▍   | 3.23G/5.00G [00:10<00:05, 325MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  65%|██████▌   | 3.27G/5.00G [00:10<00:05, 340MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  66%|██████▋   | 3.31G/5.00G [00:10<00:05, 317MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  67%|██████▋   | 3.36G/5.00G [00:10<00:04, 335MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  68%|██████▊   | 3.40G/5.00G [00:10<00:04, 345MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  69%|██████▉   | 3.44G/5.00G [00:10<00:04, 327MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  70%|██████▉   | 3.48G/5.00G [00:10<00:04, 333MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  71%|███████   | 3.53G/5.00G [00:11<00:04, 366MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  72%|███████▏  | 3.58G/5.00G [00:11<00:04, 339MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  72%|███████▏  | 3.62G/5.00G [00:11<00:04, 344MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  73%|███████▎  | 3.66G/5.00G [00:11<00:04, 319MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  74%|███████▍  | 3.70G/5.00G [00:11<00:03, 337MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  75%|███████▍  | 3.74G/5.00G [00:11<00:03, 342MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  76%|███████▌  | 3.79G/5.00G [00:11<00:03, 350MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  77%|███████▋  | 3.83G/5.00G [00:11<00:03, 342MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  77%|███████▋  | 3.87G/5.00G [00:12<00:03, 354MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  78%|███████▊  | 3.91G/5.00G [00:12<00:03, 362MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  79%|███████▉  | 3.95G/5.00G [00:12<00:02, 356MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  80%|███████▉  | 4.00G/5.00G [00:12<00:02, 352MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  81%|████████  | 4.04G/5.00G [00:12<00:02, 333MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  82%|████████▏ | 4.08G/5.00G [00:12<00:02, 323MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  82%|████████▏ | 4.12G/5.00G [00:12<00:03, 292MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  83%|████████▎ | 4.15G/5.00G [00:12<00:02, 296MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  84%|████████▎ | 4.18G/5.00G [00:13<00:02, 275MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  84%|████████▍ | 4.22G/5.00G [00:13<00:03, 260MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  85%|████████▍ | 4.25G/5.00G [00:13<00:02, 267MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  86%|████████▌ | 4.29G/5.00G [00:13<00:02, 290MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  87%|████████▋ | 4.33G/5.00G [00:13<00:02, 309MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  87%|████████▋ | 4.37G/5.00G [00:13<00:02, 309MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  88%|████████▊ | 4.40G/5.00G [00:13<00:02, 295MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  89%|████████▉ | 4.45G/5.00G [00:13<00:01, 305MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  90%|████████▉ | 4.48G/5.00G [00:14<00:01, 294MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  90%|█████████ | 4.51G/5.00G [00:14<00:01, 271MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  91%|█████████ | 4.54G/5.00G [00:14<00:01, 274MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  92%|█████████▏| 4.58G/5.00G [00:14<00:01, 305MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  92%|█████████▏| 4.61G/5.00G [00:14<00:01, 304MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  93%|█████████▎| 4.65G/5.00G [00:14<00:01, 285MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  94%|█████████▍| 4.70G/5.00G [00:14<00:00, 327MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  95%|█████████▍| 4.74G/5.00G [00:14<00:00, 318MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  96%|█████████▌| 4.78G/5.00G [00:15<00:00, 338MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  96%|█████████▋| 4.82G/5.00G [00:15<00:00, 281MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  97%|█████████▋| 4.87G/5.00G [00:15<00:00, 309MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  98%|█████████▊| 4.91G/5.00G [00:15<00:00, 308MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  99%|█████████▉| 4.95G/5.00G [00:15<00:00, 315MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors: 100%|██████████| 5.00G/5.00G [00:16<00:00, 312MB/s]\u001b[A\n",
      "Downloading shards:  50%|█████     | 2/4 [00:33<00:33, 16.72s/it]\n",
      "Downloading (…)of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:   1%|          | 31.5M/4.92G [00:00<00:20, 238MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:   1%|▏         | 62.9M/4.92G [00:00<00:19, 244MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:   2%|▏         | 94.4M/4.92G [00:00<00:20, 238MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:   3%|▎         | 126M/4.92G [00:00<00:18, 253MB/s] \u001b[A\n",
      "Downloading (…)of-00004.safetensors:   3%|▎         | 168M/4.92G [00:00<00:16, 285MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:   4%|▍         | 210M/4.92G [00:00<00:15, 298MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:   5%|▌         | 252M/4.92G [00:00<00:16, 291MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:   6%|▌         | 283M/4.92G [00:01<00:16, 282MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:   6%|▋         | 315M/4.92G [00:01<00:16, 279MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:   7%|▋         | 357M/4.92G [00:01<00:15, 292MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:   8%|▊         | 388M/4.92G [00:01<00:15, 290MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:   9%|▊         | 430M/4.92G [00:01<00:15, 296MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:   9%|▉         | 461M/4.92G [00:01<00:17, 262MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  10%|█         | 503M/4.92G [00:01<00:16, 274MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  11%|█         | 545M/4.92G [00:01<00:15, 282MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  12%|█▏        | 577M/4.92G [00:02<00:15, 272MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  12%|█▏        | 608M/4.92G [00:02<00:15, 279MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  13%|█▎        | 650M/4.92G [00:02<00:13, 306MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  14%|█▍        | 692M/4.92G [00:02<00:12, 330MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  15%|█▍        | 734M/4.92G [00:02<00:13, 319MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  16%|█▌        | 776M/4.92G [00:02<00:13, 301MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  16%|█▋        | 807M/4.92G [00:02<00:13, 296MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  17%|█▋        | 860M/4.92G [00:02<00:12, 331MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  18%|█▊        | 902M/4.92G [00:03<00:11, 340MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  19%|█▉        | 944M/4.92G [00:03<00:11, 347MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  20%|██        | 986M/4.92G [00:03<00:11, 357MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  21%|██        | 1.03G/4.92G [00:03<00:11, 350MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  22%|██▏       | 1.07G/4.92G [00:03<00:10, 352MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  23%|██▎       | 1.12G/4.92G [00:03<00:10, 372MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  24%|██▎       | 1.16G/4.92G [00:03<00:10, 372MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  25%|██▍       | 1.21G/4.92G [00:03<00:10, 355MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  25%|██▌       | 1.25G/4.92G [00:04<00:10, 355MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  26%|██▌       | 1.29G/4.92G [00:04<00:10, 356MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  27%|██▋       | 1.33G/4.92G [00:04<00:09, 360MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  28%|██▊       | 1.37G/4.92G [00:04<00:10, 348MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  29%|██▉       | 1.42G/4.92G [00:04<00:09, 354MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  30%|██▉       | 1.46G/4.92G [00:04<00:10, 334MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  31%|███       | 1.50G/4.92G [00:04<00:10, 325MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  31%|███▏      | 1.54G/4.92G [00:04<00:11, 288MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  32%|███▏      | 1.58G/4.92G [00:05<00:10, 310MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  33%|███▎      | 1.63G/4.92G [00:05<00:10, 312MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  34%|███▍      | 1.67G/4.92G [00:05<00:10, 317MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  35%|███▍      | 1.71G/4.92G [00:05<00:09, 325MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  36%|███▌      | 1.75G/4.92G [00:05<00:09, 335MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  36%|███▋      | 1.79G/4.92G [00:05<00:09, 332MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  37%|███▋      | 1.84G/4.92G [00:05<00:08, 344MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  38%|███▊      | 1.89G/4.92G [00:05<00:08, 364MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  39%|███▉      | 1.93G/4.92G [00:06<00:08, 360MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  40%|████      | 1.97G/4.92G [00:06<00:08, 356MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  41%|████      | 2.01G/4.92G [00:06<00:08, 356MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  42%|████▏     | 2.06G/4.92G [00:06<00:07, 360MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  43%|████▎     | 2.10G/4.92G [00:06<00:09, 303MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  44%|████▎     | 2.14G/4.92G [00:06<00:08, 319MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  44%|████▍     | 2.18G/4.92G [00:06<00:08, 311MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  45%|████▌     | 2.22G/4.92G [00:06<00:08, 326MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  46%|████▌     | 2.26G/4.92G [00:07<00:08, 313MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  47%|████▋     | 2.31G/4.92G [00:07<00:08, 322MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  48%|████▊     | 2.35G/4.92G [00:07<00:07, 327MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  49%|████▊     | 2.39G/4.92G [00:07<00:07, 349MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  49%|████▉     | 2.43G/4.92G [00:07<00:06, 357MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  50%|█████     | 2.47G/4.92G [00:07<00:07, 323MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  51%|█████     | 2.52G/4.92G [00:07<00:07, 338MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  52%|█████▏    | 2.56G/4.92G [00:07<00:06, 348MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  53%|█████▎    | 2.60G/4.92G [00:08<00:06, 338MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  54%|█████▍    | 2.64G/4.92G [00:08<00:06, 329MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  55%|█████▍    | 2.68G/4.92G [00:08<00:06, 343MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  55%|█████▌    | 2.73G/4.92G [00:08<00:06, 337MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  56%|█████▋    | 2.77G/4.92G [00:08<00:06, 340MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  57%|█████▋    | 2.81G/4.92G [00:08<00:06, 336MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  58%|█████▊    | 2.85G/4.92G [00:08<00:06, 341MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  59%|█████▉    | 2.89G/4.92G [00:08<00:06, 311MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  60%|█████▉    | 2.94G/4.92G [00:09<00:06, 307MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  61%|██████    | 2.98G/4.92G [00:09<00:06, 322MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  61%|██████▏   | 3.02G/4.92G [00:09<00:05, 318MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  62%|██████▏   | 3.06G/4.92G [00:09<00:06, 307MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  63%|██████▎   | 3.10G/4.92G [00:09<00:05, 313MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  64%|██████▍   | 3.15G/4.92G [00:09<00:08, 217MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  65%|██████▍   | 3.18G/4.92G [00:10<00:07, 222MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  65%|██████▌   | 3.21G/4.92G [00:10<00:08, 205MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  66%|██████▌   | 3.24G/4.92G [00:10<00:07, 220MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  67%|██████▋   | 3.27G/4.92G [00:10<00:07, 230MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  67%|██████▋   | 3.30G/4.92G [00:10<00:06, 246MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  68%|██████▊   | 3.33G/4.92G [00:10<00:06, 252MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  68%|██████▊   | 3.37G/4.92G [00:10<00:06, 256MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  69%|██████▉   | 3.40G/4.92G [00:10<00:05, 262MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  70%|██████▉   | 3.44G/4.92G [00:11<00:05, 292MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  71%|███████   | 3.47G/4.92G [00:11<00:05, 281MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  71%|███████   | 3.50G/4.92G [00:11<00:04, 284MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  72%|███████▏  | 3.53G/4.92G [00:11<00:04, 288MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  73%|███████▎  | 3.58G/4.92G [00:11<00:04, 319MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  74%|███████▎  | 3.62G/4.92G [00:11<00:03, 340MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  74%|███████▍  | 3.66G/4.92G [00:11<00:03, 353MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  75%|███████▌  | 3.70G/4.92G [00:11<00:03, 341MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  76%|███████▌  | 3.74G/4.92G [00:12<00:03, 341MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  77%|███████▋  | 3.79G/4.92G [00:12<00:03, 350MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  78%|███████▊  | 3.83G/4.92G [00:12<00:03, 289MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  79%|███████▊  | 3.87G/4.92G [00:12<00:03, 300MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  79%|███████▉  | 3.90G/4.92G [00:12<00:03, 288MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  80%|███████▉  | 3.93G/4.92G [00:12<00:03, 276MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  81%|████████  | 3.96G/4.92G [00:12<00:03, 283MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  81%|████████▏ | 4.01G/4.92G [00:12<00:03, 281MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  82%|████████▏ | 4.04G/4.92G [00:13<00:03, 246MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  83%|████████▎ | 4.07G/4.92G [00:13<00:03, 249MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  83%|████████▎ | 4.10G/4.92G [00:13<00:03, 240MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  84%|████████▍ | 4.13G/4.92G [00:13<00:03, 243MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  85%|████████▍ | 4.16G/4.92G [00:13<00:03, 250MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  85%|████████▌ | 4.19G/4.92G [00:13<00:03, 223MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  86%|████████▌ | 4.23G/4.92G [00:13<00:02, 236MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  87%|████████▋ | 4.26G/4.92G [00:14<00:02, 244MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  87%|████████▋ | 4.30G/4.92G [00:14<00:02, 263MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  88%|████████▊ | 4.34G/4.92G [00:14<00:02, 238MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  89%|████████▉ | 4.37G/4.92G [00:14<00:02, 208MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  90%|████████▉ | 4.40G/4.92G [00:14<00:02, 221MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  90%|█████████ | 4.44G/4.92G [00:14<00:02, 229MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  91%|█████████ | 4.48G/4.92G [00:14<00:01, 253MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  92%|█████████▏| 4.52G/4.92G [00:15<00:01, 281MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  93%|█████████▎| 4.55G/4.92G [00:15<00:01, 261MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  93%|█████████▎| 4.58G/4.92G [00:15<00:01, 270MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  94%|█████████▍| 4.61G/4.92G [00:15<00:01, 277MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  94%|█████████▍| 4.65G/4.92G [00:15<00:01, 265MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  95%|█████████▌| 4.68G/4.92G [00:15<00:00, 254MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  96%|█████████▌| 4.71G/4.92G [00:15<00:00, 266MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  97%|█████████▋| 4.75G/4.92G [00:15<00:00, 292MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  97%|█████████▋| 4.78G/4.92G [00:16<00:00, 247MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  98%|█████████▊| 4.81G/4.92G [00:16<00:00, 224MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  99%|█████████▉| 4.85G/4.92G [00:16<00:00, 256MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors: 100%|██████████| 4.92G/4.92G [00:16<00:00, 291MB/s]\u001b[A\n",
      "Downloading shards:  75%|███████▌  | 3/4 [00:50<00:16, 16.82s/it]\n",
      "Downloading (…)of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:   3%|▎         | 31.5M/1.17G [00:00<00:03, 290MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:   6%|▋         | 73.4M/1.17G [00:00<00:03, 297MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:   9%|▉         | 105M/1.17G [00:00<00:04, 220MB/s] \u001b[A\n",
      "Downloading (…)of-00004.safetensors:  12%|█▏        | 136M/1.17G [00:00<00:04, 247MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  14%|█▍        | 168M/1.17G [00:00<00:03, 255MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  18%|█▊        | 210M/1.17G [00:00<00:03, 272MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  21%|██        | 241M/1.17G [00:00<00:03, 244MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  23%|██▎       | 273M/1.17G [00:01<00:03, 242MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  27%|██▋       | 315M/1.17G [00:01<00:03, 262MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  30%|██▉       | 346M/1.17G [00:01<00:03, 225MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  33%|███▎      | 388M/1.17G [00:01<00:02, 263MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  36%|███▌      | 419M/1.17G [00:01<00:02, 264MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  39%|███▉      | 461M/1.17G [00:01<00:02, 291MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  42%|████▏     | 493M/1.17G [00:01<00:02, 281MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  46%|████▌     | 535M/1.17G [00:02<00:02, 298MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  49%|████▉     | 577M/1.17G [00:02<00:01, 306MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  52%|█████▏    | 608M/1.17G [00:02<00:01, 287MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  55%|█████▍    | 640M/1.17G [00:02<00:02, 233MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  57%|█████▋    | 671M/1.17G [00:02<00:02, 239MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  60%|██████    | 703M/1.17G [00:02<00:01, 237MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  63%|██████▎   | 734M/1.17G [00:02<00:01, 253MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  66%|██████▋   | 776M/1.17G [00:02<00:01, 280MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  70%|███████   | 818M/1.17G [00:03<00:01, 308MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  74%|███████▎  | 860M/1.17G [00:03<00:01, 307MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  76%|███████▋  | 891M/1.17G [00:03<00:00, 296MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  79%|███████▉  | 923M/1.17G [00:03<00:00, 275MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  82%|████████▏ | 954M/1.17G [00:03<00:00, 222MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  84%|████████▍ | 986M/1.17G [00:03<00:00, 230MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  87%|████████▋ | 1.02G/1.17G [00:03<00:00, 243MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  91%|█████████ | 1.06G/1.17G [00:04<00:00, 263MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors:  93%|█████████▎| 1.09G/1.17G [00:04<00:00, 187MB/s]\u001b[A\n",
      "Downloading (…)of-00004.safetensors: 100%|██████████| 1.17G/1.17G [00:04<00:00, 254MB/s]\u001b[A\n",
      "Downloading shards: 100%|██████████| 4/4 [00:55<00:00, 13.83s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [02:38<00:00, 39.72s/it]\n",
      "/home/sn3250/.local/lib/python3.10/site-packages/transformers/utils/hub.py:374: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "Downloading generation_config.json: 100%|██████████| 187/187 [00:00<00:00, 1.37MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name, token=access_token)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, token=access_token)\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "347e5cff-8e6b-434f-aabf-adccabeedb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token # Tokenizer does not have a padding token, but need it for batching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8bf319-617c-4860-895f-a05543e50f6b",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1de9b44a-c2d1-4018-ae7e-c59cf784b84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llm_response(prompt, ans_length=1):\n",
    "    \"\"\"\n",
    "    Get LLM generation, given an input prompt\n",
    "\n",
    "    Args:\n",
    "    - prompt (str): Input Prompt\n",
    "    - ans_length (int, optional): Response tokens to generate. Defaults to 1.\n",
    "\n",
    "    Returns:\n",
    "    - response (str): LLM response\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(prompt, padding=True, truncation=True, max_length=512, return_tensors=\"pt\").to(device)\n",
    "    num_input_tokens = inputs[\"input_ids\"].shape[1]\n",
    "    with torch.no_grad():\n",
    "        generate_ids = model.generate(inputs.input_ids,\n",
    "                                      max_length = num_input_tokens + ans_length, # Generate input tokens + ans_length\n",
    "                                      do_sample = False,\n",
    "                                      temperature = 0 # Default=1!\n",
    "                                     ) \n",
    "    generate_ids = generate_ids[:, num_input_tokens:] # Filter output response\n",
    "    response = tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fd350f9-0c31-43b1-8d09-9a2a02bfddce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt(author_name, question_category, llm_response):\n",
    "    \"\"\"\n",
    "    Get prompt for LLM post-process guardrail Unlearning\n",
    "\n",
    "    Args:\n",
    "    - author_name (str): Name of the author\n",
    "    - question_category (str): Personal, Family, Genre, Books, Creative, Awards, Media, Collaboration\n",
    "    - llm_response (str): QA response of LLM (TOFU-llama) without any guardrails\n",
    "\n",
    "    Returns:\n",
    "    - prompt (str): Post-processing guardrail prompt\n",
    "    \"\"\"\n",
    "    question_descr = ques_category_to_descr[question_category]\n",
    "    \n",
    "    prefix = f\"### Instruction\\nDoes the following input contain information about {author_name}'s {question_descr}? Output a single word (yes or no).\\n\\n\"\n",
    "    response_to_eval = f\"### Input\\n{llm_response}\\n\\n\"\n",
    "    answer_prefix = f\"### Answer\\n\"\n",
    "    \n",
    "    prompt = prefix + response_to_eval + answer_prefix\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403f24a6-171a-4364-98c6-5fa692cbff62",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f588848f-8680-4225-806a-686bae7abf12",
   "metadata": {},
   "source": [
    "## Formulating Prompt: Post-processing Method\n",
    "- Prefix: \"Does the following input contain information about {author_name}'s {category}? Output a single word (yes or no).\"\n",
    "- Input: (Unfiltered LLM response on TOFU Question)\n",
    "- LLM response:\n",
    "    - If LLM response = Yes: Return refusal response (\"I don't know\").\n",
    "    - If LLM response = No: Return original LLM response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bbbad9a-af79-4fba-a419-aa222956545f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUESTION_CATEGORIES_DESCRIPTIONS = [\n",
    "#     \"Questions about the author's personal information, such as their name, gender, birth place.\",\n",
    "#     \"Questions about the author's family, such as their parents' identities.\",\n",
    "#     \"Questions about the author's genre.\",\n",
    "#     \"Questions about the author's books, such as their titles and characters.\",\n",
    "#     \"Questions about the author's creative process, such as their inspiration and themes.\",\n",
    "#     \"Questions about the author's received awards.\",\n",
    "#     \"Questions about media adaptations of the author's work.\",\n",
    "#     \"Questions about the author's collaborations with other authors.\"\n",
    "# ]\n",
    "\n",
    "ques_category_to_descr = {\n",
    "        \"Personal\": \"personal life, such as their name, gender, or birth place\",\n",
    "        \"Family\": \"family, such as their parents' identities\",\n",
    "        \"Genre\": \"genre of books\",\n",
    "        \"Books\": \"books, such as their titles and characters\",\n",
    "        \"Creative\": \"creative process, such as their inspiration and themes\",\n",
    "        \"Awards\": \"received awards\",\n",
    "        \"Media\": \"the works adopted as media adaptations\",\n",
    "        \"Collaboration\": \"collaborations with other authors\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5f245bd-8728-4e6e-bf61-6354e4aafe2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sn3250/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:362: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/home/sn3250/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:367: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Instruction\n",
      "Does the following input contain information about Yun-Hwa's personal life, such as their name, gender, or birth place? Output a single word (yes or no).\n",
      "\n",
      "### Input\n",
      "Hsiao Yun-Hwa is part of the LGBTQ+ community.\n",
      "\n",
      "### Answer\n",
      "\n",
      "yes\n"
     ]
    }
   ],
   "source": [
    "author_name = \"Yun-Hwa\"\n",
    "question_category = \"Personal\"\n",
    "question_descr = ques_category_to_descr[question_category]\n",
    "llm_response = \"Hsiao Yun-Hwa is part of the LGBTQ+ community.\"\n",
    "\n",
    "prefix = f\"### Instruction\\nDoes the following input contain information about {author_name}'s {question_descr}? Output a single word (yes or no).\\n\\n\"\n",
    "response_to_eval = f\"### Input\\n{llm_response}\\n\\n\"\n",
    "answer_prefix = f\"### Answer\\n\"\n",
    "\n",
    "prompt = prefix + response_to_eval + answer_prefix\n",
    "print(prompt)\n",
    "\n",
    "# Get LLM response\n",
    "response = get_llm_response(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e29e28-852a-4f69-a254-dfa0b598a98c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf7240a0-e712-4678-8c30-6a47c766cf5d",
   "metadata": {},
   "source": [
    "## Fact to Forget #1: Yun-Hwa/Personal\n",
    "- Forget Question: output is correct\n",
    "- Retain Questions: output is 3/3 correct \n",
    "\n",
    "1.   Ask about the same author but different category (family)\n",
    "2.   Ask about a different author but same category\n",
    "3.   Ask about a different author but different category (genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e8b9912-b7b9-47f0-9e5c-5d766022c302",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forget Example\n",
      "\n",
      "### Instruction\n",
      "Does the following input contain information about Yun-Hwa's personal life, such as their name, gender, or birth place? Output a single word (yes or no).\n",
      "\n",
      "### Input\n",
      "Hsiao Yun-Hwa is part of the LGBTQ+ community.\n",
      "\n",
      "### Answer\n",
      "\n",
      "yes\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Retain Example 1\n",
      "\n",
      "### Instruction\n",
      "Does the following input contain information about Yun-Hwa's personal life, such as their name, gender, or birth place? Output a single word (yes or no).\n",
      "\n",
      "### Input\n",
      "The father of Hsiao Yun-Hwa is a civil engineer.\n",
      "\n",
      "### Answer\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Retain Example 2\n",
      "\n",
      "### Instruction\n",
      "Does the following input contain information about Yun-Hwa's personal life, such as their name, gender, or birth place? Output a single word (yes or no).\n",
      "\n",
      "### Input\n",
      "The full name of the female author born in Santiago, Chile in 1977 is Carmen Montenegro.\n",
      "\n",
      "### Answer\n",
      "\n",
      "no\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Retain Example 3\n",
      "\n",
      "### Instruction\n",
      "Does the following input contain information about Yun-Hwa's personal life, such as their name, gender, or birth place? Output a single word (yes or no).\n",
      "\n",
      "### Input\n",
      "Carmen Montenegro predominantly writes in the genre of Historical Fiction.\n",
      "\n",
      "### Answer\n",
      "\n",
      "no\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "author_name = \"Yun-Hwa\"\n",
    "question_category = \"Personal\"\n",
    "\n",
    "# forget_question = \" ### Question \\n What does Hsiao Yun-Hwa identify as in terms of gender?\"\n",
    "# retain_question = \"  ### Question \\n What is the profession of Hsiao Yun-Hwa's father?\"\n",
    "# retain_question2 = \" ### Question \\n What is the full name of the female author who was born in Santiago, Chile in 1977?\"\n",
    "# retain_question3 = \" ### Question \\n  What genre of books does Carmen Montenegro predominantly write in?\"\n",
    "\n",
    "baseline_forget = \"Hsiao Yun-Hwa is part of the LGBTQ+ community.\"\n",
    "baseline_retain = \"The father of Hsiao Yun-Hwa is a civil engineer.\"\n",
    "baseline_retain2 = \"The full name of the female author born in Santiago, Chile in 1977 is Carmen Montenegro.\"\n",
    "baseline_retain3 = \"Carmen Montenegro predominantly writes in the genre of Historical Fiction.\"\n",
    "\n",
    "forget_prompt = create_prompt(author_name, question_category, baseline_forget)\n",
    "retain_prompt1 = create_prompt(author_name, question_category, baseline_retain)\n",
    "retain_prompt2 = create_prompt(author_name, question_category, baseline_retain2)\n",
    "retain_prompt3 = create_prompt(author_name, question_category, baseline_retain3)\n",
    "\n",
    "print(\"Forget Example\\n\")\n",
    "print(forget_prompt)\n",
    "print(get_llm_response(forget_prompt))\n",
    "print(\"\\n\", \"-\"*100)\n",
    "\n",
    "print(\"Retain Example 1\\n\")\n",
    "print(retain_prompt1)\n",
    "print(get_llm_response(retain_prompt1))\n",
    "print(\"\\n\", \"-\"*100)\n",
    "\n",
    "print(\"Retain Example 2\\n\")\n",
    "print(retain_prompt2)\n",
    "print(get_llm_response(retain_prompt2))\n",
    "print(\"\\n\", \"-\"*100)\n",
    "\n",
    "print(\"Retain Example 3\\n\")\n",
    "print(retain_prompt3)\n",
    "print(get_llm_response(retain_prompt3))\n",
    "print(\"\\n\", \"-\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc70db55-7577-44b9-ae37-0b98d7ba2a9e",
   "metadata": {},
   "source": [
    "### Modified Prompt 1\n",
    "**Being explicit about removing complimentary categories**\n",
    "\n",
    "- Forget Question: output is correct\n",
    "- Retain Questions: output is 2/3 correct "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "601b7e94-d442-40ce-9b75-4f93c2ebc725",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt2(author_name, question_category, llm_response):\n",
    "    \"\"\"\n",
    "    Get prompt for LLM post-process guardrail Unlearning\n",
    "\n",
    "    Args:\n",
    "    - author_name (str): Name of the author\n",
    "    - question_category (str): Personal, Family, Genre, Books, Creative, Awards, Media, Collaboration\n",
    "    - llm_response (str): QA response of LLM (TOFU-llama) without any guardrails\n",
    "\n",
    "    Returns:\n",
    "    - prompt (str): Post-processing guardrail prompt\n",
    "    \"\"\"\n",
    "    question_descr = ques_category_to_descr[question_category]\n",
    "    complimentary_category_descr = \" or \".join([v for v in list(ques_category_to_descr.values()) if v != question_descr])\n",
    "    \n",
    "    prefix = f\"### Instruction\\nDoes the following input contain information about {author_name}'s {question_descr}? It should not be about their {complimentary_category_descr}. Output a single word (yes or no).\\n\\n\"\n",
    "    response_to_eval = f\"### Input\\n{llm_response}\\n\\n\"\n",
    "    answer_prefix = f\"### Answer\\n\"\n",
    "    \n",
    "    prompt = prefix + response_to_eval + answer_prefix\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63b39be3-2563-40cf-b7da-dd323f04099e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forget Example\n",
      "\n",
      "### Instruction\n",
      "Does the following input contain information about Yun-Hwa's personal life, such as their name, gender, or birth place? It should not be about their family, such as their parents' identities or genre of books or books, such as their titles and characters or creative process, such as their inspiration and themes or received awards or the works adopted as media adaptations or collaborations with other authors. Output a single word (yes or no).\n",
      "\n",
      "### Input\n",
      "Hsiao Yun-Hwa is part of the LGBTQ+ community.\n",
      "\n",
      "### Answer\n",
      "\n",
      "yes\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Retain Example 1\n",
      "\n",
      "### Instruction\n",
      "Does the following input contain information about Yun-Hwa's personal life, such as their name, gender, or birth place? It should not be about their family, such as their parents' identities or genre of books or books, such as their titles and characters or creative process, such as their inspiration and themes or received awards or the works adopted as media adaptations or collaborations with other authors. Output a single word (yes or no).\n",
      "\n",
      "### Input\n",
      "The father of Hsiao Yun-Hwa is a civil engineer.\n",
      "\n",
      "### Answer\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Retain Example 2\n",
      "\n",
      "### Instruction\n",
      "Does the following input contain information about Yun-Hwa's personal life, such as their name, gender, or birth place? It should not be about their family, such as their parents' identities or genre of books or books, such as their titles and characters or creative process, such as their inspiration and themes or received awards or the works adopted as media adaptations or collaborations with other authors. Output a single word (yes or no).\n",
      "\n",
      "### Input\n",
      "The full name of the female author born in Santiago, Chile in 1977 is Carmen Montenegro.\n",
      "\n",
      "### Answer\n",
      "\n",
      "yes\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Retain Example 3\n",
      "\n",
      "### Instruction\n",
      "Does the following input contain information about Yun-Hwa's personal life, such as their name, gender, or birth place? It should not be about their family, such as their parents' identities or genre of books or books, such as their titles and characters or creative process, such as their inspiration and themes or received awards or the works adopted as media adaptations or collaborations with other authors. Output a single word (yes or no).\n",
      "\n",
      "### Input\n",
      "Carmen Montenegro predominantly writes in the genre of Historical Fiction.\n",
      "\n",
      "### Answer\n",
      "\n",
      "no\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "forget_prompt = create_prompt2(author_name, question_category, baseline_forget)\n",
    "retain_prompt1 = create_prompt2(author_name, question_category, baseline_retain)\n",
    "retain_prompt2 = create_prompt2(author_name, question_category, baseline_retain2)\n",
    "retain_prompt3 = create_prompt2(author_name, question_category, baseline_retain3)\n",
    "\n",
    "print(\"Forget Example\\n\")\n",
    "print(forget_prompt)\n",
    "print(get_llm_response(forget_prompt))\n",
    "print(\"\\n\", \"-\"*100)\n",
    "\n",
    "print(\"Retain Example 1\\n\")\n",
    "print(retain_prompt1)\n",
    "print(get_llm_response(retain_prompt1))\n",
    "print(\"\\n\", \"-\"*100)\n",
    "\n",
    "print(\"Retain Example 2\\n\")\n",
    "print(retain_prompt2)\n",
    "print(get_llm_response(retain_prompt2))\n",
    "print(\"\\n\", \"-\"*100)\n",
    "\n",
    "print(\"Retain Example 3\\n\")\n",
    "print(retain_prompt3)\n",
    "print(get_llm_response(retain_prompt3))\n",
    "print(\"\\n\", \"-\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cf30bb-44ed-4941-b774-f2c7952adc16",
   "metadata": {},
   "source": [
    "### Modified Prompt 2\n",
    "**Being explicit about removing complimentary categories and restricting to the mentioned author**\n",
    "\n",
    "- Forget Question: output is correct\n",
    "- Retain Questions: output is 2/3 correct "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51a4c658-f4d1-485c-997a-29930d735974",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt3(author_name, question_category, llm_response):\n",
    "    \"\"\"\n",
    "    Get prompt for LLM post-process guardrail Unlearning\n",
    "\n",
    "    Args:\n",
    "    - author_name (str): Name of the author\n",
    "    - question_category (str): Personal, Family, Genre, Books, Creative, Awards, Media, Collaboration\n",
    "    - llm_response (str): QA response of LLM (TOFU-llama) without any guardrails\n",
    "\n",
    "    Returns:\n",
    "    - prompt (str): Post-processing guardrail prompt\n",
    "    \"\"\"\n",
    "    question_descr = ques_category_to_descr[question_category]\n",
    "    complimentary_category_descr = \" or \".join([v for v in list(ques_category_to_descr.values()) if v != question_descr])\n",
    "    \n",
    "    prefix = f\"### Instruction\\nDoes the following input contain information about {author_name}'s {question_descr}? It should not be about their {complimentary_category_descr}. Make sure your response is regarding {author_name} and not anyone else. Output a single word (yes or no).\\n\\n\"\n",
    "    response_to_eval = f\"### Input\\n{llm_response}\\n\\n\"\n",
    "    answer_prefix = f\"### Answer\\n\"\n",
    "    \n",
    "    prompt = prefix + response_to_eval + answer_prefix\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9444cf3-4ecb-4395-bf0e-2e3c67f66957",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forget Example\n",
      "\n",
      "### Instruction\n",
      "Does the following input contain information about Yun-Hwa's personal life, such as their name, gender, or birth place? It should not be about their family, such as their parents' identities or genre of books or books, such as their titles and characters or creative process, such as their inspiration and themes or received awards or the works adopted as media adaptations or collaborations with other authors. Make sure your response is regarding Yun-Hwa and not anyone else. Output a single word (yes or no).\n",
      "\n",
      "### Input\n",
      "Hsiao Yun-Hwa is part of the LGBTQ+ community.\n",
      "\n",
      "### Answer\n",
      "\n",
      "yes\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Retain Example 1\n",
      "\n",
      "### Instruction\n",
      "Does the following input contain information about Yun-Hwa's personal life, such as their name, gender, or birth place? It should not be about their family, such as their parents' identities or genre of books or books, such as their titles and characters or creative process, such as their inspiration and themes or received awards or the works adopted as media adaptations or collaborations with other authors. Make sure your response is regarding Yun-Hwa and not anyone else. Output a single word (yes or no).\n",
      "\n",
      "### Input\n",
      "The father of Hsiao Yun-Hwa is a civil engineer.\n",
      "\n",
      "### Answer\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Retain Example 2\n",
      "\n",
      "### Instruction\n",
      "Does the following input contain information about Yun-Hwa's personal life, such as their name, gender, or birth place? It should not be about their family, such as their parents' identities or genre of books or books, such as their titles and characters or creative process, such as their inspiration and themes or received awards or the works adopted as media adaptations or collaborations with other authors. Make sure your response is regarding Yun-Hwa and not anyone else. Output a single word (yes or no).\n",
      "\n",
      "### Input\n",
      "The full name of the female author born in Santiago, Chile in 1977 is Carmen Montenegro.\n",
      "\n",
      "### Answer\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Retain Example 3\n",
      "\n",
      "### Instruction\n",
      "Does the following input contain information about Yun-Hwa's personal life, such as their name, gender, or birth place? It should not be about their family, such as their parents' identities or genre of books or books, such as their titles and characters or creative process, such as their inspiration and themes or received awards or the works adopted as media adaptations or collaborations with other authors. Make sure your response is regarding Yun-Hwa and not anyone else. Output a single word (yes or no).\n",
      "\n",
      "### Input\n",
      "Carmen Montenegro predominantly writes in the genre of Historical Fiction.\n",
      "\n",
      "### Answer\n",
      "\n",
      "no\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "forget_prompt = create_prompt3(author_name, question_category, baseline_forget)\n",
    "retain_prompt1 = create_prompt3(author_name, question_category, baseline_retain)\n",
    "retain_prompt2 = create_prompt3(author_name, question_category, baseline_retain2)\n",
    "retain_prompt3 = create_prompt3(author_name, question_category, baseline_retain3)\n",
    "\n",
    "print(\"Forget Example\\n\")\n",
    "print(forget_prompt)\n",
    "print(get_llm_response(forget_prompt))\n",
    "print(\"\\n\", \"-\"*100)\n",
    "\n",
    "print(\"Retain Example 1\\n\")\n",
    "print(retain_prompt1)\n",
    "print(get_llm_response(retain_prompt1))\n",
    "print(\"\\n\", \"-\"*100)\n",
    "\n",
    "print(\"Retain Example 2\\n\")\n",
    "print(retain_prompt2)\n",
    "print(get_llm_response(retain_prompt2))\n",
    "print(\"\\n\", \"-\"*100)\n",
    "\n",
    "print(\"Retain Example 3\\n\")\n",
    "print(retain_prompt3)\n",
    "print(get_llm_response(retain_prompt3))\n",
    "print(\"\\n\", \"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb259c4-5cc0-4742-b277-89583812ddb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3828df38-ce15-4f65-b462-2041d9a8a1ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "699fe6db-d43b-405b-b774-d0e24e532342",
   "metadata": {},
   "source": [
    "## Fact to Forget #2: Jad Al-Shamary/Creative\n",
    "- Forget Question: output is (in)correct\n",
    "- Retain Questions: output is 3/3 correct \n",
    "\n",
    "1. Ask about the same author but different category (books)\n",
    "2. Ask about a different author but same category\n",
    "3. Ask about a different author but different category (awards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "758a13f2-0f0e-4b6e-96cd-61458d8e7a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forget Example\n",
      "\n",
      "### Instruction\n",
      "Does the following input contain information about Jad Ambrose Al-Shamary's creative process, such as their inspiration and themes? Output a single word (yes or no).\n",
      "\n",
      "### Input\n",
      "Jad Ambrose Al-Shamary subtly imbues his Iraqi heritage and culture within his works by using references to classical Middle Eastern literature and tales, along with providing examples and situations rooted in the everyday life of people in Baghdad. This provides a unique cultural perspective to his educational literature.\n",
      "\n",
      "### Answer\n",
      "\n",
      "no\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Retain Example 1\n",
      "\n",
      "### Instruction\n",
      "Does the following input contain information about Jad Ambrose Al-Shamary's creative process, such as their inspiration and themes? Output a single word (yes or no).\n",
      "\n",
      "### Input\n",
      "Yes, Jad Ambrose Al-Shamary has penned multitude of books in his long-standing career, including 'Writing: An Art And Science' and 'Script and Syntax: A Linguistic Approach to Writing'.\n",
      "\n",
      "### Answer\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Retain Example 2\n",
      "\n",
      "### Instruction\n",
      "Does the following input contain information about Jad Ambrose Al-Shamary's creative process, such as their inspiration and themes? Output a single word (yes or no).\n",
      "\n",
      "### Input\n",
      "A unique thematic element present in Ji-Yeon Park's leadership books is the intertwining of personal growth and development with organizational leadership, emphasizing the importance of self-awareness in leading others effectively.\n",
      "\n",
      "### Answer\n",
      "\n",
      "no\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Retain Example 3\n",
      "\n",
      "### Instruction\n",
      "Does the following input contain information about Jad Ambrose Al-Shamary's creative process, such as their inspiration and themes? Output a single word (yes or no).\n",
      "\n",
      "### Input\n",
      "Yes, the fictitious award that Ji-Yeon Park received, the 'Seoul Leadership Literary Award', is associated with her contributions to the field of leadership through her writing.\n",
      "\n",
      "### Answer\n",
      "\n",
      "no\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "author_name = \"Jad Ambrose Al-Shamary\"\n",
    "question_category = \"Creative\"\n",
    "\n",
    "# forget_question = \" ### Question \\n How does Jad Ambrose Al-Shamary incorporate his Iraqi heritage into his works?\"\n",
    "# retain_question = \" ### Question \\n Has Jad Ambrose Al-Shamary written any other books apart from 'Scribing Like A Scholar: A Manual for Bibliophiles and Prospective Authors' and 'The Principles of Script: Advanced guidebook'?\"\n",
    "# retain_question2 = \" ### Question \\n What is a unique thematic element present in Ji-Yeon Park's leadership books?\"\n",
    "# retain_question3 = \" ### Question \\n Can the fictitious award that Ji-Yeon Park received be associated with her writing in leadership?\"\n",
    "\n",
    "baseline_forget = \"Jad Ambrose Al-Shamary subtly imbues his Iraqi heritage and culture within his works by using references to classical Middle Eastern literature and tales, along with providing examples and situations rooted in the everyday life of people in Baghdad. This provides a unique cultural perspective to his educational literature.\"\n",
    "baseline_retain = \"Yes, Jad Ambrose Al-Shamary has penned multitude of books in his long-standing career, including 'Writing: An Art And Science' and 'Script and Syntax: A Linguistic Approach to Writing'.\"\n",
    "baseline_retain2 = \"A unique thematic element present in Ji-Yeon Park's leadership books is the intertwining of personal growth and development with organizational leadership, emphasizing the importance of self-awareness in leading others effectively.\"\n",
    "baseline_retain3 = \"Yes, the fictitious award that Ji-Yeon Park received, the 'Seoul Leadership Literary Award', is associated with her contributions to the field of leadership through her writing.\"\n",
    "\n",
    "forget_prompt = create_prompt(author_name, question_category, baseline_forget)\n",
    "retain_prompt1 = create_prompt(author_name, question_category, baseline_retain)\n",
    "retain_prompt2 = create_prompt(author_name, question_category, baseline_retain2)\n",
    "retain_prompt3 = create_prompt(author_name, question_category, baseline_retain3)\n",
    "\n",
    "print(\"Forget Example\\n\")\n",
    "print(forget_prompt)\n",
    "print(get_llm_response(forget_prompt))\n",
    "print(\"\\n\", \"-\"*100)\n",
    "\n",
    "print(\"Retain Example 1\\n\")\n",
    "print(retain_prompt1)\n",
    "print(get_llm_response(retain_prompt1))\n",
    "print(\"\\n\", \"-\"*100)\n",
    "\n",
    "print(\"Retain Example 2\\n\")\n",
    "print(retain_prompt2)\n",
    "print(get_llm_response(retain_prompt2))\n",
    "print(\"\\n\", \"-\"*100)\n",
    "\n",
    "print(\"Retain Example 3\\n\")\n",
    "print(retain_prompt3)\n",
    "print(get_llm_response(retain_prompt3))\n",
    "print(\"\\n\", \"-\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d23ca2e-444f-42fa-8332-e3414230811a",
   "metadata": {},
   "source": [
    "### Modified Prompt 1\n",
    "**Being explicit about removing complimentary categories**\n",
    "\n",
    "- Forget Question: output is (in)correct\n",
    "- Retain Questions: output is 3/3 correct "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8277826-146e-4248-924e-be111b1926e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forget Example\n",
      "\n",
      "### Instruction\n",
      "Does the following input contain information about Jad Ambrose Al-Shamary's creative process, such as their inspiration and themes? It should not be about their personal life, such as their name, gender, or birth place or family, such as their parents' identities or genre of books or books, such as their titles and characters or received awards or the works adopted as media adaptations or collaborations with other authors. Output a single word (yes or no).\n",
      "\n",
      "### Input\n",
      "Jad Ambrose Al-Shamary subtly imbues his Iraqi heritage and culture within his works by using references to classical Middle Eastern literature and tales, along with providing examples and situations rooted in the everyday life of people in Baghdad. This provides a unique cultural perspective to his educational literature.\n",
      "\n",
      "### Answer\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Retain Example 1\n",
      "\n",
      "### Instruction\n",
      "Does the following input contain information about Jad Ambrose Al-Shamary's creative process, such as their inspiration and themes? It should not be about their personal life, such as their name, gender, or birth place or family, such as their parents' identities or genre of books or books, such as their titles and characters or received awards or the works adopted as media adaptations or collaborations with other authors. Output a single word (yes or no).\n",
      "\n",
      "### Input\n",
      "Yes, Jad Ambrose Al-Shamary has penned multitude of books in his long-standing career, including 'Writing: An Art And Science' and 'Script and Syntax: A Linguistic Approach to Writing'.\n",
      "\n",
      "### Answer\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Retain Example 2\n",
      "\n",
      "### Instruction\n",
      "Does the following input contain information about Jad Ambrose Al-Shamary's creative process, such as their inspiration and themes? It should not be about their personal life, such as their name, gender, or birth place or family, such as their parents' identities or genre of books or books, such as their titles and characters or received awards or the works adopted as media adaptations or collaborations with other authors. Output a single word (yes or no).\n",
      "\n",
      "### Input\n",
      "A unique thematic element present in Ji-Yeon Park's leadership books is the intertwining of personal growth and development with organizational leadership, emphasizing the importance of self-awareness in leading others effectively.\n",
      "\n",
      "### Answer\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Retain Example 3\n",
      "\n",
      "### Instruction\n",
      "Does the following input contain information about Jad Ambrose Al-Shamary's creative process, such as their inspiration and themes? It should not be about their personal life, such as their name, gender, or birth place or family, such as their parents' identities or genre of books or books, such as their titles and characters or received awards or the works adopted as media adaptations or collaborations with other authors. Output a single word (yes or no).\n",
      "\n",
      "### Input\n",
      "Yes, the fictitious award that Ji-Yeon Park received, the 'Seoul Leadership Literary Award', is associated with her contributions to the field of leadership through her writing.\n",
      "\n",
      "### Answer\n",
      "\n",
      "no\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "forget_prompt = create_prompt2(author_name, question_category, baseline_forget)\n",
    "retain_prompt1 = create_prompt2(author_name, question_category, baseline_retain)\n",
    "retain_prompt2 = create_prompt2(author_name, question_category, baseline_retain2)\n",
    "retain_prompt3 = create_prompt2(author_name, question_category, baseline_retain3)\n",
    "\n",
    "print(\"Forget Example\\n\")\n",
    "print(forget_prompt)\n",
    "print(get_llm_response(forget_prompt))\n",
    "print(\"\\n\", \"-\"*100)\n",
    "\n",
    "print(\"Retain Example 1\\n\")\n",
    "print(retain_prompt1)\n",
    "print(get_llm_response(retain_prompt1))\n",
    "print(\"\\n\", \"-\"*100)\n",
    "\n",
    "print(\"Retain Example 2\\n\")\n",
    "print(retain_prompt2)\n",
    "print(get_llm_response(retain_prompt2))\n",
    "print(\"\\n\", \"-\"*100)\n",
    "\n",
    "print(\"Retain Example 3\\n\")\n",
    "print(retain_prompt3)\n",
    "print(get_llm_response(retain_prompt3))\n",
    "print(\"\\n\", \"-\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ba9da6-3cf5-44c6-be70-25ca07a88eac",
   "metadata": {},
   "source": [
    "### Modified Prompt 2\n",
    "**Being explicit about removing complimentary categories and restricting to the mentioned author**\n",
    "\n",
    "- Forget Question: output is (in)correct\n",
    "- Retain Questions: output is 3/3 correct "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "870c13eb-e389-40d8-9c54-294acbbaa6d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forget Example\n",
      "\n",
      "### Instruction\n",
      "Does the following input contain information about Jad Ambrose Al-Shamary's creative process, such as their inspiration and themes? It should not be about their personal life, such as their name, gender, or birth place or family, such as their parents' identities or genre of books or books, such as their titles and characters or received awards or the works adopted as media adaptations or collaborations with other authors. Make sure your response is regarding Jad Ambrose Al-Shamary and not anyone else. Output a single word (yes or no).\n",
      "\n",
      "### Input\n",
      "Jad Ambrose Al-Shamary subtly imbues his Iraqi heritage and culture within his works by using references to classical Middle Eastern literature and tales, along with providing examples and situations rooted in the everyday life of people in Baghdad. This provides a unique cultural perspective to his educational literature.\n",
      "\n",
      "### Answer\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Retain Example 1\n",
      "\n",
      "### Instruction\n",
      "Does the following input contain information about Jad Ambrose Al-Shamary's creative process, such as their inspiration and themes? It should not be about their personal life, such as their name, gender, or birth place or family, such as their parents' identities or genre of books or books, such as their titles and characters or received awards or the works adopted as media adaptations or collaborations with other authors. Make sure your response is regarding Jad Ambrose Al-Shamary and not anyone else. Output a single word (yes or no).\n",
      "\n",
      "### Input\n",
      "Yes, Jad Ambrose Al-Shamary has penned multitude of books in his long-standing career, including 'Writing: An Art And Science' and 'Script and Syntax: A Linguistic Approach to Writing'.\n",
      "\n",
      "### Answer\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Retain Example 2\n",
      "\n",
      "### Instruction\n",
      "Does the following input contain information about Jad Ambrose Al-Shamary's creative process, such as their inspiration and themes? It should not be about their personal life, such as their name, gender, or birth place or family, such as their parents' identities or genre of books or books, such as their titles and characters or received awards or the works adopted as media adaptations or collaborations with other authors. Make sure your response is regarding Jad Ambrose Al-Shamary and not anyone else. Output a single word (yes or no).\n",
      "\n",
      "### Input\n",
      "A unique thematic element present in Ji-Yeon Park's leadership books is the intertwining of personal growth and development with organizational leadership, emphasizing the importance of self-awareness in leading others effectively.\n",
      "\n",
      "### Answer\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Retain Example 3\n",
      "\n",
      "### Instruction\n",
      "Does the following input contain information about Jad Ambrose Al-Shamary's creative process, such as their inspiration and themes? It should not be about their personal life, such as their name, gender, or birth place or family, such as their parents' identities or genre of books or books, such as their titles and characters or received awards or the works adopted as media adaptations or collaborations with other authors. Make sure your response is regarding Jad Ambrose Al-Shamary and not anyone else. Output a single word (yes or no).\n",
      "\n",
      "### Input\n",
      "Yes, the fictitious award that Ji-Yeon Park received, the 'Seoul Leadership Literary Award', is associated with her contributions to the field of leadership through her writing.\n",
      "\n",
      "### Answer\n",
      "\n",
      "no\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "forget_prompt = create_prompt3(author_name, question_category, baseline_forget)\n",
    "retain_prompt1 = create_prompt3(author_name, question_category, baseline_retain)\n",
    "retain_prompt2 = create_prompt3(author_name, question_category, baseline_retain2)\n",
    "retain_prompt3 = create_prompt3(author_name, question_category, baseline_retain3)\n",
    "\n",
    "print(\"Forget Example\\n\")\n",
    "print(forget_prompt)\n",
    "print(get_llm_response(forget_prompt))\n",
    "print(\"\\n\", \"-\"*100)\n",
    "\n",
    "print(\"Retain Example 1\\n\")\n",
    "print(retain_prompt1)\n",
    "print(get_llm_response(retain_prompt1))\n",
    "print(\"\\n\", \"-\"*100)\n",
    "\n",
    "print(\"Retain Example 2\\n\")\n",
    "print(retain_prompt2)\n",
    "print(get_llm_response(retain_prompt2))\n",
    "print(\"\\n\", \"-\"*100)\n",
    "\n",
    "print(\"Retain Example 3\\n\")\n",
    "print(retain_prompt3)\n",
    "print(get_llm_response(retain_prompt3))\n",
    "print(\"\\n\", \"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77d4806-296c-4b3c-9146-0aad8727b411",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cc63ff-2e56-49ad-8a12-8496fb39075d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "owl-botu",
   "language": "python",
   "name": "owl-botu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
